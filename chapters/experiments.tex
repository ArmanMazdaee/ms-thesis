\chapter{آزمایش‌های انجام شده}
\section{مجموعه داده}
با توجه به این که \gls{amt} یک مسئله \gls{supervised learning} محسوب می‌شود،
نیاز به دادگانی است که برچسب گذاری شده باشد. به صورت کلی \glspl{dataset} مورد
استفاده در این مسئله مجموعه‌ای از زوج مرتب‌های فایل صوتی ضبط شده از یک قطعه و
همچنین آوانویسی آن قطعه می‌شود. این آوانویسی‌ها عموما به شکل فایل‌های \gls{MIDI}
هستند که در آن‌ها فعال و غیرفعال شدن نت‌ها به شکل دنباله‌ای از رخدادها مشخص شده
است. هر رخداد علاوه بر اطلاعات خود رویداد مشخص می‌کند که با چه فاصله‌ی زمانی از
آخرین رخداد قرار دارد. برای سازی مانند پیانو علاوه بر اطلاعات فعال و غیرفعال شدن
نت‌ها، رخدادهایی نیز برای مشخص کردن فعال و غیرفعال شدن پدال‌ها در نظر گرفته شده
است.

\subsection{MAPS}
MAPS یک \gls{dataset} از فایل‌های \gls{MIDI} و فایل‌های صوتی هم‌تراز آن‌ها است
که برای مسائل \gls{amt} و \gls{mpe} طراحی و آماده‌سازی شده است
\cite{emiya2009multipitch}. فایل‌های صوتی در شرایط محیطی مختلف ضبط شده‌اند و از
استاندارد CD تبعیت می‌کنند. به این معنی که هر نمونه ۱۶ بیت دقت دارد و نمونه
برداری با دقت ۴۴ کیلوهرتز انجام شده است. این \gls{dataset} شامل حدود ۶۵ ساعت
فایل صوتی است و حجم کل \gls{dataset} در حدود ۴۰ گیگابایت است. MAPS تحت مجوز
\rl{Creative Commons} به صورت عمومی منتشر شده است.

برای تولید MAPS ابتدا مجموعه‌ای عظیم از فایل‌ها \gls{MIDI} جمع‌آوری شده است. سپس
از فایل‌های \gls{MIDI} جمع‌آوری شده استفاده شده تا فایل صوتی متناظر هر کدام
تولید شود. برای تولید فایل‌های صوتی کاملا هم‌تراز با فایل‌های \gls{MIDI} از دو
روش استفاده شده است.

عمده فایل‌ها توسط نرم‌افزار ایجاد شده‌اند و از هیچ ساز فیزیکی برای تولید آن‌ها
استفاده نشده است. برای این مجموعه از فایل‌ها ابتدا فایل‌های \gls{MIDI} پشت هم
قرار داده شده‌اند تا فایل‌های \gls{MIDI} کمتر ولی با طولی بیشتر به دست آید. سپس
خروجی صوتی هر فایل توسط نرم‌افزار \lr{Steinberg’s Cubase SX} شبیه‌سازی شده است.
برای ایجاد تنوع در فایل‌های صوتی، نرم‌افزار جهت انجام شبیه‌سازی برای فایل‌های
مختلف از نمونه اجراهای پیانوهای مختلف و در شرایط محیطی متفاوت استفاده کرده است.
در نهایت فایل‌های صوتی ایجاد شده با توجه به فایل‌های \gls{MIDI} ابتدایی قطعه
قطعه شده‌اند تا اجرای متناظر هر فایل به دست آید. دلیل استفاده از فایل‌های
طولانی‌تر بجای استفاده از فایل‌های اصلی این بوده است که نرم‌افزار استفاده شده به
صورت اتوماتیک قابل کنترل نیست و برای هر ایجاد هر فایل نیاز به دخالت انسانی است.

برای بخش دیگر از فایل‌های صوتی از یک پیانو Disklavier استفاده شده است. این
خانواده از پیانوها می‌توانند از طریق ارتباط \gls{MIDI} فشرده شدن هر کلاویه را با
قدرت‌های مختلف شبیه‌سازی کنند. در نتیجه مانند این است که یک نوازنده با قدرتی
فراانسانی هر کلاویه را در زمان درست و با \gls{velocity} مشخص شده فشار دهد و
دقیقا در زمان خواسته شده آن را رها کند. همچنین برای ایجاد تنوع در فایل‌های صوتی
ضبط شده در گروهی از فایل‌ها میکروفن در فاصله نیم‌متری ساز قرار داده شده است و در
گروه دیگر میکروفن در فاصله‌ای مابین ۳ تا ۴ متری ساز قرار دارد.

نکته قابل توجه این است که فایل‌های \gls{MIDI} که برای تولید صوت در روش‌های مختلف
استفاده شده است ممکن است اشتراک داشته باشند. در نتیجه از یک قطعه ممکن است چندین
اجرای مختلف موجود باشد.

در این \gls{dataset} چهار دسته فایل \gls{MIDI} و اجراهای متناظر آن‌ها وجود دارد:
\begin{enumerate}
    \item فقط شامل اجرای مجرد نت‌های مختلف و اجراهای کوتاه
    \gls{monophonic} است. از این بخش از \gls{dataset} می‌تواند برای روش‌هایی
    مانند \gls{nmf} که نیاز به اجرای جدای نت‌ها دارند استفاده کرد.

    \item  شامل اجرای \glspl{chord} می‌شود که نت‌ها با هم هیچ ارتباط
    موسیقیایی ندارند و به صورت تصادفی در کنار هم قرار گرفته‌اند. این بخش از
    \gls{dataset} برای آزمایش عملکرد مدل‌های \gls{mpe} بدون استفاده‌ای از دانش
    موسیقی مناسب است.

    \item شامل اجرا آکوردهای رایج در موسیقی‌های غربی، مانند آکوردهای جز و یا
    آکوردهای کلاسیک، است. در نتیجه این بخش از \gls{dataset} برای سیستم‌هایی که
    از دانش موسیقیایی برای افزایش  دقت استفاده می‌کنند مناسب است.

    \item شامل ۲۳۸ قطعه موسیقی کلاسیک هست که در زمان انتشار \gls{dataset} تحت
    مجوز \rl{Creative Commons} منتشر شده بودند. تمام این فایل‌ها به صورت دستی
    پردازش شده‌اند تا هر نت کشش و \gls{velocity} مناسب را داشته باشد. این بخش از
    \gls{dataset} برای سیستم‌های \gls{amt} مناسب است.
\end{enumerate}

در این پایان‌نامه فقط از فایل‌های صوتی ضبط شده از اجرای Disklavier برای ارزیابی
استفاده شده است. دلیل این انتخاب این است که در دنیای واقعی هدف آوانویسی اجراهای
یک ساز واقعی است و اجراهای مصنوعی که توسط نرم‌افزار تولید شده‌اند اکثر جزییات یک
ساز واقعی را ندارند. همچنین تنها قطعات کامل مورد استفاده قرار گرفته‌اند تا مجددا
ارزیابی واقعاگرایانه‌تری انجام شود. در نهایت قطعات انتخاب شده دقیقا همان قطعات
استفاده شده برای ارزیابی در مدل‌های پیشنهاد شده پیشین است
\cite{hawthorne2017onsets,hawthorne2018enabling}.

علی‌رغم تمام تلاش‌های انجام شده در تهیه این \gls{dataset} همچنان چندین مشکل وجود
دارد. مشکل اول حجم کم داده است. برای مثال این \gls{dataset} تنها شامل ۶۰ نمونه
از اجرای ضبط شده واقعی است که با توجه به ماهیت مسئله بسیار محدود است. همچنین بجز
حجم کم داده، در چندین مورد فایل‌های \gls{MIDI} با نسخه‌های ضبط شده هم‌خوانی کامل
ندارند. برای مثال در قطعات مختلف اجرا نشدن نت‌های با \gls{velocity} پایین کاملا
محسوس است.

\subsection{MAESTRO}
MAESTRO یک \gls{dataset} است که توسط \cite{hawthorne2018enabling} برای رفع
مشکلات MAPS معرفی شد. این \gls{dataset} شامل بیش از ۱۷۰ ساعت اجرای موسیقی است که
طی ۱۰ سال در مسابقات \lr{Piano-e-Competition} جمع‌آوری شده است.

تمام این قطعات در کیفیت CD یا بالاتر هستند. همچنین در آوانویسی اطلاعات
\gls{velocity} نت‌ها و تغیرات پدال نگه‌دارنده نیز لحاظ شده است. آوانویسی و
اجراها با دقت ۳ میلی‌ثانیه تراز شده‌اند که حاکی از کیفیت بسیار بالای این
\gls{dataset} است. همچنین علاوه بر آوانویسی برای هر قطعه اطلاعات اضافه‌ دیگری
مانند آهنگ‌ساز و سال اجرا نیز موجود است. عمده قطعات این \gls{dataset} قطعات
کلاسیک ما بین قرن هفدهم و بیستم هستند.

این \gls{dataset} به صورت پیش‌فرض به سه بخش آموزش، صحت‌سنجی و ارزیابی به گونه‌ای
تقسیم شده است که اجراهای متفاوت از یک قطعه در بخش‌ها متفاوت قرار نگیرند. در جدول
زیر اطلاعات مربوط به هر بخش نشان داده شده است.
\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        بخش & تعداد اجرا & تعداد قطعه & زمان به ساعت & حجم به گیگابایت & تعداد نت به میلیون \\
        \hline
        آموزش & ۹۵۴ & ۲۹۵ & ۱۴۰/۱ & ۸۳/۶ & ۵/۰۶ \\
        \hline
        صحت‌سنجی & ۱۰۵ & ۶۰ & ۱۵/۳ & ۹/۱ & ۰/۵۴ \\
        \hline
        ارزیابی & ۱۲۵ & ۷۵ & ۱۶/۹ & ۱۰/۱ & ۰/۵۷ \\
        \hline
        مجموع & ۱۱۸۴ & ۴۳۰ & ۱۷۲/۳ & ۱۰۲/۸ & ۶/۱۸ \\
        \hline
    \end{tabular}
    \caption{اطلاعات \gls{dataset} MAESTRO}
\end{table}

\section{معیارهای ارزیابی}
معیارهای استفاده شده برای ارزیابی بسیار نزدیک به معیارهای پیشنهاد شده در مسابقات
MIREX است که توسط کتابخانه \lr{mir-eval} \cite{raffel2014mir_eval} پیاده‌سازی
شده‌اند.

برای ارزیابی ابتدا از \gls{dataset} مجموعه‌ای از سه‌تایی‌های مرتب مرتبط با هر
قطعه استخراج می‌شود. هر کدام از این سه‌تایی‌های مرتب نشان دهنده یک نت هستند و
اعضای آن به ترتیب فرکانس نت، زمان شروع و زمان پایان نت را نشان می‌دهند. به این
ساختار ذخیره‌سازی موسیقی دنباله نت می‌گوییم. همچنین پس از انجام آوانویسی توسط
مدل، خروجی مدل از ساختار \gls{pianoroll} توسط الگوریتمی که در ادامه بحث می‌شود
به دنباله نت تبدیل می‌شود.

برای ارزیابی نیاز هست که تشخیص دهیم که کدام یک از نت‌های تشخیص داده شده توسط مدل
واقعا در قطعه حضور دارند، چه تعداد حضور ندارند و مدل چه تعداد از نت‌ها را تشخیص
نداده است. همچنین با توجه به این که میزان کمی خطا در زمان‌ها و یا فرکانس نت‌های
تشخیص داده شده طبیعی است، معیارهای استفاده شده نیاز به مقداری انعطاف‌پذیری نیز
دارند.

به این منظور گرافی دو بخشی ایجاد می‌شود که راس‌های یک بخش نت‌های استراخ شده از
\gls{dataset} هستند و راس‌های بخش دیگر نت‌های تشخیص داده شده توسط مدل هستند. در
صورتی که بتوان دو راس مختلف از دو بخش را برابر دانست بین‌ آن‌ها یالی قرار
می‌دهیم در غیر این صورت دو راس به هم مرتبط نیستند. همچنین شرط برابر بودن نت‌ها
وابسته به معیار متفاوت است که در ادامه برای هر معیار این شرط بررسی می‌شود.

پس از تشکیل گراف ذکر شده، تطابق بیشینه گراف محاسبه می‌شود تا مشخص شود که چه
نت‌هایی به درستی تشخیص داده شده‌اند و چه نت‌های اشتباه تشخیص داده شده‌اند و یا
تشخیص داده نشده‌اند. پس از محاسبه این تطابق می‌توان از طریق روابط زیر مقادیر
\gls{precision}، \gls{recall} و F1 را برای معیار مورد نظر محاسبه کرد:
\begin{equation}
    precision = \frac{TP}{TP + FP}
\end{equation}
\begin{equation}
    recall = \frac{TP}{TP + FN}
\end{equation}
\begin{equation}
    F1 = 2 \frac{precision . recall}{precision + recall}
\end{equation}

$TP$ تعداد نت‌هایی هست که به درستی تشخیص داده شده‌اند که برابر با اندازه تطابق
محاسبه شده است. $FP$ نت‌هایی هستند که مدل تشخیص داده است ولی واقعا وجود ندارند.
این عدد برابر با راس‌های از بخش مربوط به نت‌های تشخیص داده شده توسط مدل هستند که
در تطابق نیستند. همچنین $FN$ تعداد نت‌هایی هست که مدل نتوانسته تشخیص دهد. تعداد
این نت‌ها برابر با راس‌هایی از بخش استخراج شده از \gls{dataset} است که عضو تطابق
نیستند.

شرط برابر فرض شدن دو نت با توجه به معیار مورد نظر متفاوت است. معیار اول فقط به
شروع نت‌ها تشخیص داده شده اهمیت می‌دهد. در نتیجه دو نت یکسان فرض می‌شوند اگر
\gls{pitch} آن‌ها کمتر از ربع‌پرده اختلاف داشته باشد و همچنین تفاوت زمان شروع
آن‌ها کمتر از ۵۰ میلی‌ثانیه باشد.

معیار بعدی علاوه بر شروع نت‌ها به زمان پایان نت‌ها نیز اهمیت می‌دهد. در نتیجه
برای برابر فرض شدن دو نت علاوه بر شروط قبلی، دو نت باید اختلاف زمان پایانشان
کمتر از بیشینه ۵۰ میلی‌ثانیه و یک پنچم طول نت مرجع باشد.

\section{تبدیل دادگان}
اطلاعات موجود در \gls{dataset} به صورت مستقیم برای آموزش مدل و ارزیابی عملکرد آن
قابل استفاده نیستند. فایل‌های صوتی ابتدا نیاز دارند تا به نرخ نمونه‌گیری شانزده
کیلوهرتز برده شوند و سپس سیگنال به دست آمده تبدیل به \gls{spec} شود. همچنین
فایل‌های \gls{MIDI} باید تبدیل به نمایش دنباله نت شوند. در فاز آموزش این
دنباله نت‌های به دست آماده تبدیل به \gls{pianoroll} می‌شوند تا برچسب‌ها مورد
نیاز آموزش شبکه به دست آید. همچنین با توجه به این که خروجه شبکه نیز یک
\gls{pianoroll} است، برای ارزیابی به فرآیندی برای تبدیل مجدد به دنباله نت نیاز
است. در ادامه هر کدام از این تبدیل‌ها بررسی می‌شوند.

\subsection{تبدیل صوت به اسپکتروگرام}
در قدم اول نیاز هست تا فایل‌های صوتی \gls{dataset} به نرخ نمونه‌گیری شانزده
کیلوهرتز برده شوند. با توجه به این که زیرترین نت پیانو فرکانسی برابر ۴۱۸۶ هرتز
دارد، پس نرخ نمونه‌گیری شانزده کیلوهرتز می‌تواند تمام اطلاعات نت‌ها را نگه‌دارد
و بخش ارزشمندی از اطلاعات از دست نرود. همچنین در صورتی که صوت ورودی بیشتر از یک
کانال داشته باشد قبل از تغییر نرخ نمونه‌گیری، با میانگین گرفتن بین کانال‌های
مختلف، صوت را تبدیل به یک سیگنال تک‌کاناله می‌کنیم.

در قدم بعدی نیاز است که این سیگنال صوتی به دست آمده به فضای فرکانس برده شود.
برای این منظور بر روی سیگنال به دست آماده تبدیل mel را اعمال می‌کنیم. در این
تبدیل از پنجره هنینگ به طول ۲۰۴۸ نمونه، برابر ۱۲۸ میلی‌ثانیه، برای محاسبه
فریم‌ها استفاده می‌شود. همچنین در هر مرحله پنجره را اندازه ۵۱۲ نمونه، برابر ۳۲
میلی‌ثانیه، حرکت می‌دهیم. بم‌ترین فرکانس محاسبه شده برابر ۳۰ هرتز است و در نهایت
\gls{spec} خروجی به ازای هر فریم، یک بردار با اندازه ۲۲۹ خواهد بود.

\subsection{تبدیل MIDI به دنباله‌ی نت}
اطلاعات در فایل‌های \gls{MIDI} به شکل دنباله‌ای از رخدادها ذخیره می‌شوند. هر
رخداد از سه بایت تشکیل شده که شامل اطلاعاتی همچنین نوع رخداد و فاصله زمانی از
رخداد قبلی می‌شود. مهم‌ترین این رخدادها رخدادهای فعال شدن و غیر فعال شدن نت‌ها
هستند. همچنین در پیانو رخداد تغییر وضعیت پدال \gls{sustain} نیز اهمیت زیادی
دارد.

پدال \gls{sustain} در پیانو به این شکل عمل می‌کند که در زمان فشرده بودن پدال حتی
اگر کلاویه توسط نوازنده رها شود، نت همچنان فعال می‌ماند. نت فعال تنها در صورت
تمام می‌شود که نوازنده مجددا همان کلاویه را فشار دهد یا پدال \gls{sustain} را
رها کند. در نتیجه برای تولید دنباله‌ی نت از فایل \gls{MIDI} توجه به تغییرات پدال
\gls{sustain} لازم است در دنباله نت خروجی باید هر نت تا پایان فعال بودن پدال،
فعال نگه‌داشته شود.

\section{تبدیل دنباله‌ی نت به رول پیانو}
هر \gls{pianoroll} شامل دو ماتریس است که به ترتیب نشان‌دهنده فعال شدن و غیر فعال
شدن نت‌ها می‌باشند. هر ماتریس ۸۸ ستون دارد که متناظر با ۸۸ کلاویه پپانو است.
همچنین هر سطر از این ماتریس‌ها نماینده یک فریم است.

به صورت سنتی ماتریس دوم بجای نشان‌دهنده غیرفعال شدن یک نت، نشان‌دهنده فعال بودن
یا نبودن هر نت در یک فریم بوده است. با توجه به این موضوع که تشخیص غیرفعال شدن نت
در صوت، به علت ایجاد تفاوت محسوس‌تر بین دو فریم متوالی، ساده‌تر است، در این
پایان‌نامه تصمیم گرفته شد که بجای تشخیص فعال بودن نت‌ها، غیرفعال شدن هر نت تشخیص
داده شود.

برای تبدیل کافی است تا زمان شروع و پایان هر نت بر طول هر فریم، که در این
پایان‌نامه برابر ۳۲ میلی‌ثانیه است، تقسیم شود تا شماره ستون فریم متناظر به دست
آید. سپس در ماتریس اول درایه متناظر با کلاویه و فریم شروع فعال شدن نت و در
ماتریس دوم درایه متناظر با کلاویه و فریم غیر فعال شدن نت یک شود. همچنین اگر فریم
فعال شدن و غیر فعال شدن یک نت یکی شد، از آن نت صرف نظر می‌شود. در الگوریتم ۱
تبدیل دنباله نت به \gls{pianoroll} را نشان داده است.

\begin{algorithm}[ht]
\caption{تبدیل دنباله نت به \gls{pianoroll}}
\begin{algorithmic}
\begin{latin}
    \Require $notesequence$
    \Ensure $onsets$, $offsets$
    \State $notesequence\_duration \leftarrow$ max of all end times
    \State $num\_frames \leftarrow \lfloor notesequence\_duration / frame\_duration \rfloor + 1$
    \State $onsets \leftarrow$ zero matrix of size $num\_frames \times 88$
    \State $offsets \leftarrow$ zero matrix of size $num\_frames \times 88$
    \For {$note$ in $notesequence$}
        \State $pitch \leftarrow note.pitch$
        \State $onset \leftarrow \lfloor note.start\_time / 0.032 \rfloor$
        \State $offset \leftarrow \lfloor note.end\_time / 0.032 \rfloor$
        \If {$onset$ is $end$}
            \State continue
        \EndIf
        \State $onsets_{onset, pitch} \leftarrow 1$
        \State $offsets_{offset, pitch} \leftarrow 1$
    \EndFor
\end{latin}
\end{algorithmic}
\end{algorithm}

\subsection{تبدیل رول پیانو به دنباله‌ی نت}
برای ارزیابی عملکرد مدل لازم است تا \gls{pianoroll} تولید شده توسط مدل به یک
دنباله نت تبدیل شود. با این که به صورت سنتی از \gls{hmm} برای این تبدیل استفاده
می‌شود ولی نشان داده شده است که یک الگوریتم ساده نیز می‌تواند نتایج مشابه بدهد و
نیازی به سربار محاسباتی اضافه \gls{hmm} وجود ندارد.

کافی است که به ازای هر \gls{pitch}، در ستون متناظر با آن از ابتدا شروع به حرکت
کنیم. اگر در ماتریس اول مقدار یک درایه بیشتر از حدنساب ۰/۵ شد نت مورد بررسی از
آن فریم به بعد فعال فرض می‌شود. اگر به ازای یک نت فعال مجددا تشخیص فعال شدن نت
داده شد، نت فعال قبلی تمام می‌شود و نت دیگری از آن‌جا آغاز می‌شود. هرگاه در
ماتریس دوم مقدار پیش‌بینی شده از حدنساب بیشتر شد، در صورت موجود بودن یک نت فعال،
آن نت تمام شده فرض می‌شود. در الگوریتم ۲ تبدیل \gls{pianoroll} به دنباله‌ی نت
نشان داده شده است.
\begin{algorithm}[ht]
\caption{تبدیل \gls{pianoroll} به دنباله‌ی نت}
\begin{algorithmic}
\begin{latin}
    \Require $onsets$, $offsets$
    \Ensure $notesequence$
    \State $notesequence \leftarrow \emptyset$
    \State $num\_frames \leftarrow onsets.shape[0]$
    \For {$pitch$ from $0$ to $88$}
        \State $start \leftarrow null$
        \For {$frame$ from $0$ to $num\_frames$}
            \State $is\_onset \leftarrow onsets_{frame, pitch} \geq 0.5$
            \State $is\_offset \leftarrow offsets_{frame, pitch} \geq 0.5$
            \If {$is\_onset$ and $start$ is $null$}
                \State $start \leftarrow frame$
            \ElsIf {$is\_onset$ and $start$ is not $null$}
                \State $note \leftarrow Note()$
                \State $note.pitch \leftarrow pitch$
                \State $note.start\_time \leftarrow start * 0.032$
                \State $note.end\_time \leftarrow frame * 0.032$
                \State $notesequence \leftarrow notesequence \cup note$
                \State $start \leftarrow frame$
            \ElsIf {$is\_offset$ and $start$ is not $null$}
                \State $note \leftarrow Note()$
                \State $note.pitch \leftarrow pitch$
                \State $note.start\_time \leftarrow start * 0.032$
                \State $note.end\_time \leftarrow frame * 0.032$
                \State $notesequence \leftarrow notesequence \cup note$
                \State $start \leftarrow null$
            \EndIf
        \EndFor
        \If {$start$ is not $null$}
            \State $note \leftarrow Note()$
            \State $note.pitch \leftarrow pitch$
            \State $note.start\_time \leftarrow start * 0.032$
            \State $note.end\_time \leftarrow num\_frames * 0.032$
            \State $notesequence \leftarrow notesequence \cup note$
        \EndIf
    \EndFor
\end{latin}
\end{algorithmic}
\end{algorithm}

\subsection{کوتاه‌سازی دنباله‌ها}
به علت طولانی بودن \gls{spec} و \gls{pianoroll} هیچ کدام از مدل‌های بررسی شده در
ادامه امکان بررسی یک دنباله کامل را به علت محدودیت حافظه ندارند. برای حل این
مشکل در زمان آموزش، هر دنباله به دنباله‌های کوچیک‌تر به طول ۱۰۰۰ فریم، برابر ۳۲
ثانیه، شکسته می‌شوند. همچنین اگر دنباله‌ای پس از تجزیه طولی کمتر از ۱۵۰ فریم، ۴/۸
ثانیه، داشته باشد از فرایند آموزش حذف می‌شود.

در زمان ارزیابی نیز این تجزیه لازم است. هر دنباله ورودی به مدل ابتدا به
دنباله‌هایی به طول حداکثر ۱۰۰۰ فریم شکسته می‌شوند. همچنین به هر دنباله ۱۰۰ عضو
قبلی و بعدی، در صورت وجود، افزوده می‌شود. این عضوهای ورودی صرفا برای دادن
اطلاعات محیطی بیشتر به مدل هستند و از خروجی مدل حذف می‌شود. پس از آن که مدل کل
یک دنباله را مشاهده کرد، دنباله‌ها خروجی با توجه به ترتیب اولیه به هم متصل
می‌شوند و سپس مورد ارزیابی قرار می‌گیرند.

\section{آزمایش‌ها}
\subsection{مدل آوایی ساده}
در آزمایش اول تنها یک مدل آوایی بسیار ساده بررسی شده است. این مدل تنها شامل ۳
لایه پیچشی تک بعدی است که روی هم قرار گرافته‌اند. سپس خروجی لایه آخر به دو شبکه
\gls{fully connected} داده می‌شود تا دو ماتریس \gls{pianoroll} را تولید کنند.

هر لایه پیچشی استفاده شده در مدل کرنلی با اندازه سه دارند و شامل ۵۱۲
\gls{feature map} می‌باشند. دلیل استفاده از لایه پیچشی این است که بررسی تغییرات
هر فریم زمانی با داشتن اطلاعات فریم‌های اطراف بسیار ساده‌تر هست. این لایه‌ها از
تابع فعال‌ساز ReLU استفاده می‌کنند.

دولایه \gls{fully connected} خروجی هر کدوم شامل ۸۸ نرون خروجی می‌شوند. این دو
لایه بر روی هر فریم به صورت مستقل اعمال می‌شوند و از تابع فعال‌ساز sigmoid
استفاده می‌کنند. در نتیجه هر درایه ماتریس‌های خروجی مانند یک دسته‌بندی دوگانه
است که مشخص می‌کند هر نت در چه فریمی شروع شده و در چه فریمی پایان یافته است.

نکته قابل توجه در مورد این مدل این است که شامل هیچ ساختاری برای پردازش دنباله‌ی
اطلاعات نیست و تصمیم‌گیری در مورد فعال یا غیرفعال شدن نت‌ها در هر فریم تنها
بر اساس فریم‌های ورودی همسایه رخ می‌دهد. در نتیجه این مدل تقریبا هیچ گونه
اطلاعاتی درباره ساختار موسیقی را نمی‌تواند فرابگیرد.

برای محاسبه خطای خروجی‌ها از تابع خطای \gls{cross entropy} استفاده شده است. با
توجه به نامتوازن بودن برچسب‌های خروجی، درایه‌هایی که مقدار حقیقی آن‌ها یک بوده
است، خطایشان ابتدا در ۵ ضرب شده است و سپس از مقدار خطای کل درایه‌های دو ماتریس
میانگین گرفته شده است تا خطای نهایی بدست آید.

در طول آموزش از الگوریتم بهینه‌سازی ADAM برای تنظیم وزن‌های شبکه استفاده شده
است. همچنین مقدار نرخ یادگیری طی ۴۰۰۰ مرحله اولیه آموزش افزایش یافته است و سپس
مجددا کاهش داده شد. با استفاده از تابع زیر می‌توان مقدار نرخ یادگیری در هر مرحله
را محاسبه کرد:
\begin{equation}
    lr(step) =
    \begin{cases}
        0.003 * \frac{step}{4000} &\quad step \leq 4000\\
        0.003 * \frac{1}{\sqrt{step - 4000}} &\quad step > 4000\\
    \end{cases}
\end{equation}

پس از آموزش شبکه برای ۱۰۰۰۰ مرحله با اندازه دسته ۱۶ به نتایج زیر دست یافته شد:
\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        & \multicolumn{3}{|c|}{تنها شروع نت} & \multicolumn{3}{|c|}{شروع و پایان نت} \\
        \hline
        دیتاست & \gls{precision} & \gls{recall} & F1 & \gls{precision} & \gls{recall} & F1 \\
        \hline
        MAPS & ۰/۶۳۴ & ۰/۶۴۲ & ۰/۶۳۸ & ۰/۴۳۰ & ۰/۴۳۸ & ۰/۴۳۴ \\
        \hline
        MAESTRO & ۰/۷۶۰ & ۰/۷۶۲ & ۰/۷۶۱ & ۰/۶۱۳ & ۰/۶۰۹ & ۰/۶۱۱ \\
        \hline
    \end{tabular}
    \caption{نتایج مدل آوایی ساده}
\end{table}

\subsection{مدل آوایی پیچیده}
در مدل آوایی پیچیده به مدل این قابلیت داده شده است که علاوه بر توانایی بررسی
همسایگی هر فریم برای تشخیص فعال و غیرفعال شدن نت‌ها، بتواند به فریم‌های دورتر هم
نگاه کند و از اطلاعات آن‌ها نیز برای تصمیم گیری استفاده کند. به این ترتیب مدل
می‌تواند قوانین موسیقیایی را نیز به صورت ضمنی فرا بگیرد و از آن‌ها برای افزایش
دقت خود استفاده کند.

در ابتدا مجددا ۳ لایه پیچشی تک بعدی وجود دارد که ساختاری دقیقا مشابه لایه‌های
استفاده شده در مدل آوایی ساده دارند. خروجی پس از اعمال \gls{positional encoding}
به بخش \gls{encoder} یک \gls{transformer} داده می‌شود. این بخش به مدل این قابلیت
را می‌دهد که محتوای فریم‌های دورتر را نیز بررسی کند و بر اساس آن‌ها تصمیم بگیرد.
بخش \gls{encoder} استفاده شده شامل ۸ لایه می‌شود. \gls{multi-head attention}
استفاده شده در داخل آن ابعادی برای ۵۱۲ دارد و شامل ۴ سر می‌شود. همچنین لایه
\gls{fully connected} بعد از هر \gls{multi-head attention} ۲۰۴۸ نرون خروجی دارد.

در نهایت خروجی به دو لایه \gls{fully connected} مجزا داده می‌شود تا دو ماتریس
\gls{pianoroll} را پیش‌بینی کنند. این لایه‌ها هم کاملا مشابه لایه‌های \gls{fully
connected} انتهایی مدل آوایی ساده می‌باشند.

تابع خطا و الگوریتم بهینه‌سازی کاملا مشابه مدل آوایی ساده هستند. این مدل پس از
آموزش دیدن به ازای ۲۰۰۰۰ مرحله با اندازه دسته ۱۶ توانست به نتایج زیر دست پیدا
کند.
\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        & \multicolumn{3}{|c|}{تنها شروع نت} & \multicolumn{3}{|c|}{شروع و پایان نت} \\
        \hline
        دیتاست & \gls{precision} & \gls{recall} & F1 & \gls{precision} & \gls{recall} & F1 \\
        \hline
        MAPS & ۰/۷۱۰ & ۰/۷۱۱ & ۰/۷۱۰ & ۰/۵۱۶ & ۰/۵۱۲ & ۰/۵۱۴ \\
        \hline
        MAESTRO & ۰/۸۴۲ & ۰/۸۳۷ & ۰/۸۴۰ & ۰/۶۹۶ & ۰/۶۹۰ & ۰/۶۹۳ \\
        \hline
    \end{tabular}
    \caption{نتایج مدل آوایی پیچیده}
\end{table}

همان گونه که از نتایج مشخص است، با این که تنها تفاوت این مدل با مدل قبل اضافه
کردن ساختاری برای استفاده از اطلاعات به دست آماده از فریم‌های دورتر است، دقت این
مدل به شکل قابل توجهی افزایش یافته است. در نتیجه می‌توان گفت که مدل به صورت ضمنی
دارد قواعد موسیقی را در این لایه‌ها فرا می‌گیرد و با کمک آن‌ها پیش‌بینی لایه‌های
اولیه را بهبود می‌دهد.

\subsection{بکارگیری مدل موسیقیایی پیشنهادی}
در \gls{asr} استفاده از یک مدل زبانی که فقط بر روی متن آموزش دیده شده است و درک
مناسبی از قواعد زبانی دارد، می‌تواند دقت مدل آوایی را به خوبی افزایش دهد و نتایج
رضایت‌بخشی به دست آورد. در \gls{asr} مدل زبانی با کمک الگوریتم جست‌جوی beam در هر
مرحله خروجی مدل آوایی را اصلاح می‌کند. در \gls{amt} به علت مشکلاتی مانند طول
بسیار زیاد دنباله‌های ورودی استفاده از الگوریتم جست‌وجوی beam ممکن نیست. در
ادامه ابتدا یک روش آموزش مدل موسیقیایی را معرفی می‌شود. سپس یک روش برای ترکیب
این مدل با یک مدل آوایی بررسی می‌شود.

\subsubsection{مدل موسیقیایی}
این مدل تنها بر روی آوانویسی در شکل \gls{pianoroll} آموزش داده می‌شود. در نتیجه
مدل دو ورودی می‌گیرد که دو ماتریس \gls{pianoroll} می‌باشند. این دو ماتریس به هم
در بعد \gls{pitch} متصل می‌شود و سپس به سه لایه \gls{fully connected} پشت هم
داده می‌شوند. هر کدام از این لایه‌ها ۵۱۲ خروجی دارند.

سپس در زمان آموزش ۳۰ درصد فریم‌های به دست آمده به صورت تصادفی انتخاب می‌شوند و
مقدار آن‌ها صفر می‌شود در نتیجه اطلاعات مربوط به آن فریم‌ها کاملا از دست می‌رود.
ماتریس جدید پس از اعمال \gls{positional encoding} به بخش \gls{encoder} یک مدل
\gls{transformer} با ساختاری کاملا مشابه ساختار استفاده شده در مدل آوایی پیچیده
داده می‌شود. خروجی این ساختار مجددا به دو لایه \gls{fully connected} داده می‌شود
که هر کدام مربوط به یک ماتریس \gls{pianoroll} می‌باشند. این دو لایه نهایی نیز
ساختاری کاملا مشابه با مدل آوایی پیچیده دارند.

برای آموزش مدل از تابع خطا و الگوریتم بهینه‌سازی دو مدل قبل استفاده می‌شود. تنها
تفاوت این است که خطا فقط بر روی فریم‌هایی محاسبه می‌شود که فریم ورودی متناظر آن‌ها
صفر شده است. به این ترتیب مدل باید تلاش کند با استفاده از اطلاعات موجود، مقدار
فریم‌های صفر شده را حدس بزن. در نتیجه درک مناسبی از قواعد موسیقی به دست می‌آورد.
این سیستم آموزش یک مدل موسیقیایی مشابه سیستمی است که برای آموزش مدل زبانی BERT
استفاده می‌شود \cite{devlin2018bert}.

همچنین با توجه به این که مدل تنها بر روی آوانویسی آموزش داده می‌شود به راحتی
می‌توان داده موجود را تشدید کرد. برای این منظور قبل از تبدیل دنباله نت به
\gls{pianoroll} مقدار تمام نواک‌ها در عددی رندم ما بین -۵ تا ۵ جمع می‌شود.
همچنین تمام زمان‌های شروع و پایان نیز در عدد رندمی ما بین ۰/۹ تا ۱/۱ ضرب می‌شود.
هر چند که دنباله نت‌های به دست آمده متفاوت هستند ولی دقیقا یک قطعه را توصیف
می‌کند تنها با این تفاوت که قطعه در کلیدی متفاوت در سرعتی متفاوت نواخته شده است.

\subsubsection{ترکیب با مدل آوایی}
از مدل موسیقیایی آموزش دیده در مرحله قبل لایه‌های \gls{fully connected} ابتدایی
حذف می‌شوند با ۳ لایه پیچشی یک بعدی با وزن‌های تصادفی جایگزین می‌شوند. مدل به
دست آمده کاملا مشابه مدل آوایی پیچیده است. برای آموزش دقیقا مانند مدل آوایی
پیچیده عمل می‌شود تنها با این تفاوت که وزن لایه‌های به دست آمده از مدل موسیقیایی
در طی آموزش تغییر نمی‌کنند.

پس از آموزش برای ۱۰۰۰۰ مرحله با اندازه دسته ۱۶ نتایج زیر از این مدل به دست
می‌آید.
\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|c|c|c|c|}
        \hline
        & \multicolumn{3}{|c|}{تنها شروع نت} & \multicolumn{3}{|c|}{شروع و پایان نت} \\
        \hline
        دیتاست & \gls{precision} & \gls{recall} & F1 & \gls{precision} & \gls{recall} & F1 \\
        \hline
        MAPS & ۰/۷۳۲ & ۰/۷۳۱ & ۰/۷۳۱ & ۰/۵۲۱ & ۰/۵۲۷ & ۰/۵۲۴ \\
        \hline
        MAESTRO & ۰/۸۵۲ & ۰/۸۵۱ & ۰/۸۵۱ & ۰/۶۹۷ & ۰/۷۰۲ & ۰/۶۹۹ \\
        \hline
    \end{tabular}
    \caption{نتایج به دست آمده از ترکیب مدل موسیقیایی با مدل آوایی}
\end{table}

با وجود این که مدل کاملا مشابه مدل آوایی پیچیده است دقت مدل پیش‌رفت داشته است.

\section{جمع‌بندی}
در این فصل ابتدا \gls{dataset} مورد استفاده در این پایان‌نامه معرفی شدند. سپس با
معیارهای ارزیابی مدل‌های مسئله \gls{amt} آشنا شدیم. همچنین در ادامه الگوریتم‌های
پردازش \gls{dataset} بررسی شدن. درنهایت یک مدل موسیقیایی پیشنهاد شد و یک روش
جدید برای به کارگیری آن در حل مسئله \gls{amt} بررسی شد.