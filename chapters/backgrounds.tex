\chapter{مروری بر مفاهیم مورد نیاز}
\section{تبدیلات سیگنال صوتی}
یک اجرای موسیقی می‌تواند کاملا توسط تغییرات ایجاد شده در فشار هوا طی زمان توصیف
شود. این نمایش به صورت سنتی محور افقی نماینده زمان است و محور عمودی نماینده
تغییرات ایجاد شده در فشار یا شدت سیگنال است. با توجه به این که کامپیوترها
توانایی پردازش اطلاعت پیوسته را ندارند، این سیگنال‌ها نیاز دارند تا گسسته‌سازی
شوند. با توجه به این گوش انسان می‌تواند اصواتی با فرکانس تا ۲۰ کیلوهرتز را بشنود
و پردازش کند، برای این که تمام اطلاعات مورد نیاز بتواند ذخیره شود، نمونه برداری
با حداقل دقت ۴۰ کیلوهرتز انجام شود. به صورت رایج موسیقی معمولا در ۴۴/۱ کیلوهرتز
نمونه برداری می‌شود. همچنین برای ذخیره هر نمونه از ۱۶ بیت استفاده می‌شود.
فایل‌های wav از این نمایش برای ذخیره سازی موسیقی استفاده می‌کنند.

هر چند که صوت تنها حاصل نوسانات ماده است، ولی سیستم شنوایی این نوسانات به
مجموعه‌ای از فرکانس‌ها تبدیل می‌شود و سپس پردازش می‌شوند. برای تشخیص میزان وجود
یک فرکانس خاص در یک سیگنال صوتی می‌توان همبستگی سیگنال صوتی را با یک سیگنال
سینوسی در فرکانس خواسته شده را محاسبه کرد. هرچند دو سیگنال سینوسی با فرکانس
یک‌سان نیز می‌توانند همبستگی صفر داشته باشند اگر فاز آن‌ها به میزان مناسبی با هم
اختلاف داشته باشد. این موضوع به خوبی در شکل زیر نشان داده شده است.
\begin{figure}[ht]
    \centering
    \includegraphics[height=5cm]{./statics/uncorrelated_sine_waves.png}
    \caption{دو سیگنال سینوسی که با هم وابستگی ندارند ولی هر دو در فرکانس یکسانی نوسان می‌کنند}
\end{figure}

برای اندازگیری همبستگی به ازای تمام فازهای ممکن، مانند فازی که باعث می‌شود تا
مقدار همبستگی حداکثر شود، از اعداد موهومی استفاده می‌شود. فرض کنید نقطه‌ای برروی
محور اعداد موهومی از مبدا و در جهت اعداد حقیقی مثبت شروع به حرکت کند. جهت حرکت
این نقطه با با توجه به فرکانس خواسته شده تغییر می‌کنند. همچنین سرعت حرکت این
نقطه در لحظه $t$ برابر با قدرت سیگنال ورودی در  لحظه $t$ است. به عبارتی دیگر،
نقطه یاد شده در زمان $t$ به اندازه قدرت سیگنال ورودی در زمان $t$ و در جهت محاسبه
شده جابه‌جا می‌شود. در پایان فرآیند هرچه نقطه از مبدا دورتر شده باشد، یعنی
وابستگی سیگنال ورودی با سیگنالی سینوسی با فرکانسی برابر فرکانس خواسته شده بیشتر
است. همچنین فازی که باعث بیشتر مقدار وابستگی می‌شود، با جهت کلی حرکت در ارتباط
هست. شکل زیر نمونه‌ای از انجام این فرآیند را برای دو سیگنال مختلف نشان می‌دهد.
مطابق انتظار برای سیگنالی که هم بستگی بسیار پایینی با فرکانس خواسته شده دارد،
نقطه نزدیک مبدا است و برای سیگنالی که همبستگی بیشتری دارد، از مبدا دورتر است.
\begin{figure}[ht]
    \centering
    \includegraphics[height=8cm]{./statics/spectral_domain_process.png}
    \caption{انجام فرایند توضیح داده شد بر روی دو سیگنال ورودی مختلف}
\end{figure}

فرایند بالا را می‌توان توسط رابطه زیر مدل کرد:
\begin{equation}
    X(\omega) = \sum_{n} x(n)e^{i \omega \frac{2\pi}{f_s} n}
\end{equation}
که $X(\omega)$ عددی موهومی است که اندازه آن برابر است با میزان حضور یک فرکانس
دلخواه مانند $\omega$ در سیگنال ورودی $x$. همچنین $x(n)$ میزان قدرت سیگنال در در
نمونه $n$ نشان می‌دهد. $e^{i \omega \frac{2\pi}{f_s}}$ برابر جهت حرکت در محور‌
مختصات اعداد موهومی در زمان $t = \frac{n}{f_s}$ است که $f_s$ فرکانس خواسته شد
است. محل توقف نقطه در فرآیند یاد شده همان خروجی این رابطه است که اندازه آن با
میزان حضور فرکانس مطلوب در سیگنال ورودی رابطه دارد.

با کمک رابطه بالا می‌توان می‌توان میزان وجود هر فرکانس در سیگنال ورودی را اندازه
گرفت و در نتیجه سیگنال ورودی را به حوزه فرکانس انتقال داد. حوزه فرکانس میزان
قدرت هر فرکانس در سیگنال ورودی را بیان می‌کند در حالی که حوزه زمان که ابتدا سیگنال
در آن بود قدرت سیگنال در زمان‌های مختلف را مشخص می‌کند.

\subsection{تبدیل فوریه}
معروف‌ترین تبدیل برای انتقال سیگنال از حوزه زمان به حوزه فرکانس تبدیل فرویه هست.
\gls{fft} یک پیاده سازی از این تبدیل است که سیگنال‌هایی که طول آن‌ها توانی از دو
است را می‌توان در $O(nlog(n))$ به حوزه فرکانس ببرد. این تبدیل میزان فعال بودن
فرکانس‌های مختلف را که فاصله خطی از هم دارند را به گونه‌ای محاسبه می‌کند که
سیگنال ابتدایی مجدد بعد از تبدیل قابل محاسبه است. این تبدیل سیگنال ورودی را به
شکل حاصل جمع مجموعه‌ای موج سینوسی با فرکانس‌های مختلف بیان می‌کند. صورت گسسته
این تبدیل که به \gls{dft} معروف است توسط رابطه زیر قابل محاسبه است:
\begin{equation}
    X[k] = \sum_{n=0}^{N-1} x[n]e^{- ikw\omega_0n} \quad \forall k \in \{ 0, 1, ..., N-1 \}
\end{equation}
که $x$ سیگنال ورودی به طول $N$ است و $\omega_0$ برابر $\frac{2\pi}{n}$ است.

همچنین برای بازتولید سیگنال اولیه می‌توان از رابطه زیر استفاده کرد:
\begin{equation}
    x[n] = \frac{1}{N}\sum_{k=0}^{N-1} X[k]e^{ik\omega_0n} \quad \forall n \in \{ 0, 1, ..., N-1 \}
\end{equation}

به صورتی کلی وقتی خروجی تبدیل بررسی می‌شوند تنها اندازه اعداد موهومی به دست آمده
استفاده می‌شود. اندازه این اعداد متناسب با همبستگی سیگنال ورودی با سیگنال‌های
سینوسی بهینه است.

با توجه به سرعت \gls{fft} این تبدیل از حوزه‌های متفاوت به صورت گسترده استفاده
می‌شود. با این وجود در حوزه \gls{mir} این تبدیل یک ضعف مهم دارد. به کمک این
تبدیل می‌توان متوجه شد که یک فرکانس خاص، مثلا ۴۴۰ هرتز، در یک قطعه وجود دارد ولی
راهی برای تشخیص مکان وجود این فرکانس وجود ندارد. یک راه حل برای این ضعف این است
که سیگنال ورودی در فواصل کوتاه برش داده شود و برای هر برش به صورت جداگانه تبدیل
محاسبه گردد. این تبدیل جدید به \gls{stft} معروف است. هرچی فاصله زمانی که برش‌ها
در آن‌ها انجام می‌شود کوتاه‌تر باشد، دقت خروجی در بعد زمان بیشتر است. از طرفی
دیگر کوتاه بودن این فواصل زمانی باعث کاهش دقت در بعد فرکانس می‌شود. خروجی
\gls{STFT} یک نمایش دو بعدی است که یک محور آن نماینده زمان و محور دیگر نماینده
فرکانس است. این نمایش به نمایش زمان-فرکانس معروف است.

\subsection{تبدیل ثابت Q}
یکی از ضعف‌های \gls{stft} در حوزه موسیقی این است که فرکانس‌هایی که وجود آن‌ها در
سیگنال ورودی بررسی می‌شود، فاصله خطی از یک دیگر دارند. این در حالی هست که
\gls{pitch} نت‌های موسیقی در فواصل لگاریتمی از یک دیگر قرار دارند. این تفاوت‌ به
این معنی است که برای نت‌های بم تعداد زیادی فرکانس وجود دارد ولی برای نت‌های
زیرتر فرکانس‌های کمتری وجود دارد.

\gls{cqt} بجای استفاده از فواصل خطی از فواصل لگاریتمی استفاده می‌کند. ایده اصلی
این است که در فرایند توضیح داده شده در ابتدا، فرکانس‌های انتخابی، فاصله‌ای
لگاریتمی نسبت به هم داشته باشند. همچنین این تبدیل به کمک توابع پنجره‌بندی تنها
در بازه‌های زمانی خاصی، وجود فرکانس‌ها را بررسی می‌کند.
\begin{figure}
    \centering
    \includegraphics[height=4cm]{./statics/windowed_signal.png}
    \caption{نمونه‌ای از یک سیگنال پنجره‌بندی شده}
\end{figure}

\gls{CQT} را می‌توان به کمک رابطه زیر محاسبه کرد:
\begin{equation}
    X^{CQ}(k, n) = \sum_{j=n-\lfloor N_k / 2 \rfloor}^{n+\lfloor N_k / 2 \rfloor} x(j)a_k^*(j-n+N_k/2) \quad \forall k \in \{1, 2, ..., K \}
\end{equation}
\begin{equation}
    a_k^*(n) = \frac{1}{N_k} w (\frac{n}{N_k}) e^{if_k\frac{2\pi}{f_s}n}
\end{equation}
$X^{CQ}(k, n)$ مقدار خروجی تبدیل برای فرکانس $f_k$ و در اطراف نمونه $n$ سیگنال
ورودی $x$ است. $N_k$ یک عدد حقیقی هست که از پارامترهای تبدیل است. $w$ یک تابع
پنجره‌بندی پیوسته هست که دامنه آن بین صفر و یک است. $f_k$ فرکانس خواسته شده‌
$k$ام است. $f_s$ نیز فرکانسی است که سیگنال ورودی با آن نمونه برداری شده است.

این تبدیل پارامترهای مختلفی دارد که مقدار بهینه آن‌ها با توجه به معیار‌هایی
مانند توانایی باز تولید سیگنال و سرعت محاسبه در \cite{schorkhuber2010constant}
بررسی شده است. در ادامه به بررسی این پارامترها می‌پردازیم.

$f_k$ مقدار فرکانس $k$ام خواسته شده را مشخص می‌کند. با توجه به این که این
فرکانس‌ها با هم فاصله‌ای لگاریتمی دارند، می‌توان مقدار آن‌ها را مقایسه کرد. برای
محاسبه می‌توان از رابطه زیر استفاده کرد:
\begin{equation}
    f_k = f_1 2^{\frac{k-1}{B}} \quad \forall k \in \{1, 2, ..., K\}
\end{equation}
$f_1$ یا $f_{min}$ مقدار پایین‌ترین فرکانس را مشخص می‌کند که سایر فرکانس‌ها از
آن شروع می‌شوند. $B$ مشخص می‌کند به ازای هر اکتاو چند فرکانس انتخاب شود و میزان
حضور آن‌ها در سیگنال ورودی اندازه گرفته شود. همچنین $K$ تعداد کل فرکانس‌های
خواسته شده است. این مقدارها با توجه کاربرد به می‌توانند انتخاب شوند.

$N_k$ عرض پنجره استفاده شده برای فرکانس $k$ام را مشخص می‌کند. مقدار بهینه این
پارامتر را می‌توان با استفاده از رابطه زیر محاسبه کرد:
\begin{equation}
    N_k = \frac{qf_s}{f_k(2^{\frac{1}{b}}-1)} \stackrel{B \geq 12}{\approx} \frac{qf_sB}{log(2)f_k} \quad 0 < q \leq 1
\end{equation}

انجام \gls{cqt} برای هر نمونه نه از نظر محاسبه منطقی است و نه مزیت خاصی دارد. از
این جهت این تبدیل به ازای هر $H_k$ نمونه یک بار انجام می‌شود. مقدار بهینه برای
این پارامتر برابر $\lfloor \frac{1}{2N_k} \rfloor$ است تا تمام طول سیگنال ورودی
پردازش شود. همچنین در عمل معمولا به ازای تمام مقادیر $k$، $H_k = H$ است تا خروجی
را بتوان به شکل یک ماتریس نمایش داد.

$w$ تابع پنجره‌بندی مورد استفاده است که به صورت سنتی از تابع $Hann$ برای آن
استفاده می‌شود. این تابع برشی از تابع سینوس‌ هست که در زیر نمودار آن نشان داده شده
است.
\begin{figure}[ht]
    \centering
    \includegraphics[height=5cm]{./statics/hann_plot.png}
    \caption{نمودار تابع پنجره‌بندی Hann}
\end{figure}

در نهایت $f_s$ فرکانس نمونه‌برداری از سیگنال اولیه است. برای صحت محاسبات رابطه
زیر باید برقرار باشد:
\begin{equation}
    f_s \geq 2f_k
\end{equation}

\subsection{اسپکتروگرام mel}
با توجه به این که درک انسان از صوت یک درک کاملا لگاریتمی نیست، مقیاس دیگری برای
انجام آزمایشات ساخته شده است که به مقیاس mel معروف است. با وجود این که بیش از یک
مقیاس mel ساخته شده، ولی تمام آن‌ها تنها تفاوت‌هایی جزئی با هم دارند. در این
پایان‌نامه فقط یکی از این مقیاس‌ها توضیح داده شده است که همان مقیاسی است که در
این پایان‌نامه استفاده شده است و کتابخانه librosa آن را پیاده‌سازی کرده است
\cite{mcfee2015librosa}.

آزمایشات انجام شده بر روی شنوایی انسان نشان داده‌اند که درک انسان از صوت، تا
هزار هرتز، یک درک خطی است. برای اصوات بالای هزار هرتز این درک به شکل لگاریتمی در
می‌آید. با این توصیف رابطه زیر می‌تواند این مقیاس را مدل کند:
\begin{equation}
    x Hz =
    \begin{cases}
        \frac{3x}{200}mel &\quad x \leq 1000\\
        15 + 27 ln(x/1000) / ln(6.4) mel &\quad \text{elsewhere}
    \end{cases}
\end{equation}

کتاب‌خانه librosa \gls{spec} با مقیاس mel را به کمک رابطه زیر محاسبه می‌کند:
\begin{equation}
    X^{MEL}(k, n) = \sum_{j=0}^{n_{fft}-1} |X_n|^2(j)A_k^*(\frac{f_s}{n_{fft}}j)
\end{equation}
$|X_n|$ اندازه \gls{dft} سیگنال ورودی $x$ در اطراف $n$ با $n_{fft}$ نمونه است.
$A_k^*$ یک تابع پنجره‌بندی از اعداد حقیقی به اعداد حقیقی است. این تابع شکلی
مثلثی دارد و در $f_{k-1}$ مقدار صفر دارد. در $f_k$ به $V_{max}^{k}$ می‌رسد و
مجددا در $f_{k+1}$ صفر می‌شود. $V_{max}^{k}$ به گونه‌ای مقدار داده می‌شود که
تقریبا برای هر کانال مقداری ثابت داشته باشد. این مقدار از رابطه زیر به دست
می‌آید:
\begin{equation}
    V_{max}^{k} = \frac{2}{f_{k+1} - f_{k-1}}
\end{equation}
$\frac{f_s}{n_{fft}}j$ فرکانس متناظر با $j$امین فرکانس استفاده شده در \gls{dft}
است. همچنین $f_s$ فرکانس نمونه‌گیری سیگنال ورودی $x$ است.

\subsection{قالب فرکانسی یک نت}
وقتی که صوت حاصل از اجرای یک نت تنها، از حوزه زمان به خوزه فرکانس انتقال داده
شود، \gls{spec} به دست آمده، قالب فرکانس آن نت نامیده می‌شود. وقتی که

در شکل زیر قالب فرکانسی نت $A5$ که بر روی ساز پیانو اجرا شده است رسم شده است.
همچنین فرکانس‌ها با یک دیگر فاصله‌ای لگاریتمی دارند تا متناظر با \gls{pitch}
نت‌های پیانو باشند. همچنین که در \gls{spec} رسم شده کاملا واضح است، علاوه بر
فرکانس پایه نت، فرکانس‌های پایه‌ای دیگری نیز کامل در صوت تولید شده حضور دارند.
این فرکانس‌ها با خط سفید مشخص شده‌اند. این پدیده رفتاری کاملا انتظار از یک ساز
موسیقی است و یکی از عوامل اصلی سختی مسئله \gls{atm} محسوب می‌شود. همچنین این
رفتار وجه اصلی تمایز مسئله \gls{asr} با مسئله \gls{atm} است. این فرکانس‌‌های
فعال، به عنوان هامونیک‌های نت نواخته شده شناخته می‌شود. با توجه به این که این
هامونیک‌ها خود متناظر با نت‌های دیگری نیز هستند که احتمال نواخته شدن بالایی نیز
با نت پایه دارند، تشخیص نت‌های فعال را بسیار پیچیده می‌کنند.

همچنین، با توجه به شکل کاملا واضح است که در لظحه نواخته شدن نت، فرکانس‌های فعال
دیگری نیز در صوت تولید شده حضور دارند. دلیل حضور این فرکانس‌ها این است که وقتی
یک سیم پیانو توسط چکش نواخته می‌شود، در لحظه شروع حجم زیادی نویز تولید می‌کند که
باعث حضور بازه گسترده‌ای از فرکانس‌ها می‌شود. ولی پس از گذشت زمانی کوتاه، سیم
شروع می‌کند به در فرکانس متناظر نوسان کردن و فرکانس‌های اضافه حذف می‌شوند. حضور
این بازه گسترده از فرکانس‌ها باعث می‌شود که شروع نت‌ها به شکل بسیار ساده‌تری
قابل تشخیص باشد.
\begin{figure}[ht]
    \centering
    \includegraphics[width=15cm]{./statics/a5_spec.png}
    \caption{\gls{spec} متناظر با نواخته شدن نت A5 بر روی پیانو}
\end{figure}

\section{یادگیری ژرف}
در سال‌های اخیر، \gls{ml} روز به روز محبوب‌تر شده‌است در برای حل مسائلی مانند
دسته‌بندی تصاویر، پیشنهاد ویدیو، تحلیل شبکه‌های اجتماعی و پردازش متن به صورت
گسترده استفاده می‌شود. در میان روش‌های \gls{ml}، \gls{dl} موفقیت‌های بسیاری برای
حل این مسائل و مسائل دیگر به دست آورده است. رشد نمایی داده و پیشرفت‌های
سخت‌افزاری باعث شده که تحقیقات گسترده‌ای بر روی \gls{dl} صورت بپذیرد. \gls{dl}
که پیدایش آن ریشه در \gls{nn} دارد، توانسته به خوبی از پدران خود پیشه بگیرد و
نتایج بسیاری بهتری به دست بیاورد. روش‌های اخیر در \gls{dl} نتایج بسیار امیدوار
کننده‌ای در حوزه‌های پردازش تصویر، گفتار و زبان طبیعی به دست آورده‌اند و در خیلی
از مسائل انسان حتی پیشه گرفته‌اند.

به صورت سنتی، نمایشی که برای برای داده انتخاب می‌شود، تاثیر به سزایی در دقت
نهایی سیستم دارد و یک نمایش نامناسب از داده باعث دقت به‌شدت پایین‌تری می‌شده
است. از این جهت بررسی شیوه‌های موثر نمایش داده، در \gls{ml}، از چالش‌های اصلی
حوزه محسوب می‌شده است و مطالعات زیادی بر روی آن‌ها انجام شده است. با این وجود
این یافته‌ها اکثرا تنها محدود به حوزه خاصی هستند و قابل تعمیم به سایر حوزه‌ها
نیستند.

در مقابل، در \gls{dl}، تمام این فرایند استخراج ویژگی از داده‌های ورودی و تبدیل
آن‌ها به نمایشی مناسب، به صورت خوکار، توسط مدل فراگرفته و اعمال می‌شود. این
ویژگی این خانواده از مدل‌ها باعث می‌شود که نیاز به دخالت متخصص حداقل شود و
سیستم‌هایی کارا، بدون نیاز دانش حوزه، طراحی شوند.

سیستم‌های مبتنی بر \gls{dl} شامل مجموعه‌ای از لایه‌های غیرخطی هستند که می‌توانند
اطلاعات را در ساختاری سلسله‌مراتبی استخراج کنند. لایه‌های ابتدایی مدل، مسئول
استخراج ویژگی‌های سطح پایین‌تر هستند. سپس لایه‌های بعدی از این ویژگی‌های استخراج
شده استفاده می‌کنند تا ویژگی‌های سطح بالاتری را استخراج کنند. این دقیقا همان
رفتاری است که مغز انسان برای پردازش داده‌های ورودی و تصمیم‌گیری بر اساس آن‌ها
انجام می‌دهد. برای مثال در سیستم بینایی انسان، نرون‌های ابتدایی تنها وظیفه
استخراج نقطه‌ها را دارند. از موقعیت نقطه‌های استخراج شده استفاده می‌شود تا خطوط
تشخیص داده شوند. به همین شکل مغز اشکال پیچیده‌تر را پیدا می‌کند و تشخیص می‌دهد
در لحظه در حال مشاهده چه اجسامی می‌باشد.

\subsection{تاریخچه یادگیری ژرف}
ساختن ماشینی که مشابه مغز انسان کار کند و بتواند مانند مغز مسائل را حل کند
رویایی به قدمت چندین قرن برای دانشمندان است با این حال شروع تاریخجه مدرن
\gls{dl} را می‌توان از ۱۹۴۳ دانست که \lr{McCulloch-Pitts} معرفی شد. این مدل
اولین مدل ساختار نرون محسوب می‌شود و نمونه‌ای اولیه از \gls{nn} امروزی است. مدل
معرفی شده می‌توانست تا حدی رفتار یک نرون مغزی را مدل کند ولی هیچ قاعده‌ای برای
یادگیری معرفی شد. از آن زمان \gls{dl} به آرامی شروع به پیداش و پیشرفت کرد و طی
چندین رخداد مهم تبدیل به ساختار امروزی شد.

پس از معرفی مدل \lr{McCulloch-Pitts} قاعده یادگیری هب معرفی شد که ریشه‌ای زیستی
دارد و برای آموزش شبکه‌های اولیه استفاده می‌شود. سپس در سال ۱۹۵۸ در حوزه علوم
شناختی، مدل پرسپترون معرفی شد که ساختاری بسیار نزدیک به \gls{nn} امروزی دارد. با
پایان یافتن دوره رکود اولی \gls{ai}، پیدایش \gls{backpropagation} رخداد تارخی
مهم بعدی در پیدایش \gls{dl} بود. به کمک \gls{backpropagation} آموزش \gls{nn} به
کمک یک تابع خطا ممکن شد. در سال ۱۹۸۰ neocogitron معرفی شد که منجر به پیدایش
\gls{cnn} شد. همچنین در سال ۱۹۸۶ با معرفی \gls{rnn} امکان پردازش داده‌های
دنباله‌ای محقق شد. در نهایت در ده ۹۰ میلادی با معرفی LeNet اولین شبکه عصبی عمیق
معرفی شد. هرچند این شبکه در زمان انتشار، به علت محدودیت‌های سخت‌افزاری به شهرت
زیادی دست نیافت.

در ۲۰۰۶ \gls{dbn} همراه با یک شیوه آموزش لایه به لایه معرفی شدند. ایده اصلی این
شبکه‌ها این بود که یک شبکه دولایه ساده با \gls{unsupervised learning} و مشابه
\gls{rbm} آموزش داده شود. سپس تمام پارامترهای فراگرفته شده قفل شوند، یک لایه
جدید در ادامه شبکه قرار داده شود، و پارامترهای این لایه همچون لایه قبل فراگرفته
شود. با کمک این شیوه آموزش، محققان توانستند شبکه‌هایی با عمق به شدت بیشتر از
مدل‌های قبلی را آموزش دهند. \gls{dl} بعد از سال‌ها توسعه و با ریشه در \gls{nn}
یکی از روش‌های پرطرفدار در \gls{ml} محسوب می‌شوند که توانسته است موفقیت‌های
زیادی به دست آورد.

از موفقیت‌های اخیر \gls{dl} می‌توان از AlphaGo نام برد که در ابتدای ۲۰۱۷ توسط
تیمی از گوگل معرفی شد و با عملکرد خود دنیا را متعجب ساخت. این مدل توانست تحت نام
مستعار master، ۶۰ بازی Go در مقابل حریفان حرفه‌ای برنده شود. از جمله این
پیروزی‌ها سه برد پیاپی در مقابل \lr{Ke Jie} است. این شبکه توانست با بهره‌گیری از
روش‌های مدرن \gls{dl} و سخت‌افزاری قدرتمند برای آموزش، قهرمان چهانی این بازی را
شکست دهد.

\subsection{شبکه‌های عصبی مصنوعی}
شبکه‌های عصبی مصنوعی سیستم‌های محاسباتی هستند که از شبکه‌های عصبی زیستی الهام
گرفته‌اند. این سیستم‌ها از طریق مشاهده مثال‌ها و بدون نیاز به برنامه‌ریزی مستقیم
می‌توانند مسائل مختلفی را حل کنند. برای مثال این شبکه‌ها با دیدن تصاویر زیادی که
حاوی ماشین بوده‌اند، در تصاویر جدید ماشین را، بدون نیاز به تعریف مستقیم ماشین،
تشخیص دهند. از این جهت از شبکه‌های عصبی مصنوعی در حل مسائلی که نمی‌توان به راحتی
از طریق الگوریتم‌های قانونمند برای حل آن‌ها اقدام کرد، استفاده می‌شود.

یک شبکه عصبی مصنوعی از تعداد زیادی واحدهای کوچک‌تر که یک نرون مصنوعی نامیده
می‌شوند تشکیل شده است. این نرون‌ها توسط اتصالاتی به نام سیناپس به یکدیگر مرتبط
اند که می‌تواند سیگنال‌ها را از نرونی به نرون بعدی منتقل کند. به این طریق هر
نرون می‌تواند مجموعه‌ای از سیگنال‌های ورودی را گرفته، آن‌ها را پردازش کند و از
طریق سیگنالی نتیجه را به نرون‌های بعدی منتقل کند. همچنین این سیناپس‌ها معمولا
دارای وزن‌هایی می‌باشند که میزان اهمیت یک سیگنال برای نرون دریافت کننده آن را
نشان می‌دهد و فرآیند یادگیری شامل تنظیم این وزن‌ها است.

به طور معمول نرون‌ها به شکل لایه لایه قرار داده می‌شنود که هر لایه عمل مخصوص به
خود را انجام می‌دهد و نتیجه را به لایه بعد منتقل می‌کند. برای مثال شبکه‌ای را در
نظر بگیرید که هدف آن تشخیص اشیای مختلف باشد. این شبکه از لایه‌های مختلفی تشکیل
شده است. در فرآیند یادگیری ممکن است این لایه اول نسبت به خطها حساس شده باشد.
یعنی هر نرون این لایه در صورت وجود خطی با زاویه و ضخامتی مشخص و در جایی مشخص از
تصویر، سیگنال‌های شدیدتری به لایه بعدی ارسال کند. حال لایه بعد می‌تواند از
اطلاعات ارسالی از لایه قبل استفاده کرده، و با توجه به اطلاعات خطها شکل‌های هندسی
ساده را تشخیص دهد.

هدف اصلی شبکه‌های عصبی مصنوعی پردازش اطلاعات و حل مسائل به همان شیوه‌ای بود که
مغز انسان مسائل را حل می‌کند. ولی در طول زمان با تمرکز بروی مسائل مختلف باعث شد
عملکردهایی اضافه شوند که گاها هیچ توجیح زیستی‌ای ندارند. به عنوان نمونه می‌توان
به فرآیند پس‌انتشار خطا اشاره کرد که با این که هیچ ریشه زیستی ندارند ولی یکی از
اصلی‌ترین شیوه‌های آموزش شبکه‌های عصبی عمیق محسوب می‌شود.

با گذر زمان و افزایش توان محاسباتی کامپیوترها، دانشمندان توانستند شبکه‌های عصبی
بزرگ‌تر و پیچیده‌تری طراحی کنند و با استفاده از آن‌ها مسائل سخت‌تری را حل
نمایند. در حال حاضر هر شبکه ممکن است تا حدود چند میلیون نرون داشته باشد. با این
حال هنوز تا شبکه‌هایی به پیچیدگی مغز انسان که راه بسیاری باقی مانده است.

\subsection{روش‌های یادگیری}
روش‌های \gls{dl} را می‌توان به سه دسته \gls{supervised learning}،
\gls{unsupervised learning} و \gls{semisupervised learning} تقسیم کرد. همچنین
\gls{reinforcement learning} نیز دسته دیگری از روش‌ها را شامل می‌شود که خود زیر مجموعه‌ای از
روش‌های \gls{semisupervised learning} است.

\gls{supervised learning} روش‌هایی هستند که از برچسب داده‌گان برای آموزش استفاده
می‌کنند. در این خانواده از روش‌ها دادگان به شکل زوج مرتب $(x, y)$ هستند که $x$
ورودی مدل است و $y$ خروجی مورد نظر است. در صورتی که مدل به ازای ورودی $x$ مقدار
$y^{\prime}$ را برگداند، مقادیر $y$ و $y^\prime$ به یک تابع خطا، مثلا $L$، داده
می‌شوند و پارامترهای مدل به گونه‌ای تغییر داده می‌شود که مقدار $L(y, y^\prime)$
کاهش یابد. پس از پایان آموزش انتظار می‌رد که در صورتی که ورودی $x$ به مدل داده
شود، مدل بتواند جواب درست، $y$ را تشخیص دهد و برگرداند.

\gls{unsupervised learning} به روش‌هایی گفته می‌شود که داده‌گان مورد آموزش در
آن‌ها دارای برچسب نمی‌باشد. در این روش‌ها مدل تلاش می‌کند تا ساختار داخلی یا
ویژگی‌های مهم ورودی را فراگیرد و با کمک آن‌ها روابط بین داده‌گان ورودی را
پیدا کند. \gls{clustering} و \gls{dimensionality reduction} نمونه‌هایی از مسائل
\gls{unsupervised learning} محسوب می‌شوند.

\gls{semisupervised learning} به روش‌هایی اطلاق می‌شود که تنها بخشی از دادگان
آموزش آن‌ها دارای برچسب هستند. در این روش‌ها معمولا بخشی از مدل توسط روش‌های
\gls{unsupervised learning} و بخش دیگر توسط روش‌های \gls{supervised learning}
آموزش داده می‌شود.

\subsection{طراحی و آموزش شبکه‌ها عصبی عمیق}
طراحی شبکه‌های عصبی شامل تعیین تعداد لایه‌ها، نوع و اندازه هر لایه، شیوه ارتباط
لایه‌ها و تابع خطا با توجه ماهیت مسئله مورد نظر است. این پارامترها که ساختار مدل
را مشخص می‌کنند با نام \gls{hyper parameter} شناخته می‌شوند.

فرض کنید یک شبکه عصبی یک تابع هست که می‌خواهد تقریبی از تابع $f$ از $X$ به $Y$
باشد. نمونه‌هایی از مقادیر $X$ و مقدار متناظر آن‌ها در $Y$ به شکل \gls{dataset}
آموزش داده شده‌اند. ساختار استفاده شده برای شبکه، شکل این تابع مشخص می‌کند و
محدودیتی بر روی ساختار آن اعمال می‌کند. از این جهت در زمان طراحی تلاش می‌شود تا
ساختار به گونه‌ای انتخاب شود که محدودیت‌های اعمال شده مانع انعطاف پذیری مورد
نیاز تابع نشوند و تابع ظرفیت کافی برای تقریبی مناسب را دارا باشد. همچنین تابع
انعطاف پذیری بیشتر از مقدار مورد نیاز نیز نداشته باشد تا منجر به \gls{overfit}
نشود.

پس از طراحی، وزن‌های شبکه به عنوان پارامترهای شبکه محسوب می‌شوند. به عبارتی دیگر
خروجی شبکه، $y^\prime$، به صورت تابعی از ورودی شبکه، $x$، و وزن‌های شبکه، $w$
است. در این مرحله با معرفی تابع خطا، $J(w)$، تفاوت بین مقدار خروجی شبکه،
$y^\prime$ و مقدار مورد نظر، $y$، اندازه گرفته می‌شود. این تابع خطا به گونه‌ای
انتخاب می‌شود که کاهش مقدار آن به معنای نزدیک شدن شبکه به تابعی که قصد تقریب آن
را داشتیم باشد تا مسئله حل شود.

آموزش شبکه یک فرآیند تکرار شونده از تنظیم وزن‌های شبکه، $w$، به گونه‌ای است که
مقدار تابع خطا، $J(w)$، کاهش یابد. تابع خطا یک روش برای ارزیابی خروجی‌های شبکه
با توجه مقدار درست آن‌ها است. یک روش مناسب برای کاهش مقدار تابع خطا استفاده از
\gls{backpropagation} و \gls{gd} است که در هر مرحله مقدار وزن‌های شبکه، $w$، را
به شکلی تغییر می‌دهد که مقدار تابع خطا، $J(w)$، بیشترین کاهش را داشته باشد.
\gls{gd} را توسط رابطه زیر می‌توان مدل کرد:
\begin{equation}
    w := w - \eta \nabla J(w)
\end{equation}
که $\eta$ نرخ یادگیری و $\nabla J(w)$ گرادیان $J(w)$ هستند. همچنین برای محاسبه
گرادیان $J(w)$ از الگوریتم \gls{backpropagation} استفاده می‌شود که با استفاده از
قاعده زنجیره‌ای مشتق در هر لایه گرادیان را محاسبه می‌کند.

سرعت آموزش شبکه تاثیر به شدت بالایی بر روی دقت نهایی سیستم دارد. دلیل این امر
این است که اگر دو شبکه با سرعت خیلی تفاوتی آموزش داده شوند، ممکن است در نقاط
مختلفی همگرا شوند و در نتیجه تفاوت زیادی در دقت نهایی داشته باشند. همچنین اگر
سرعت یادگیری از حد بیشتر شود، ممکن است شبکه حتی همگرا نشود و دقت حتی کاهش پیدا
کند. با توجه به رابطه بالا مشخص است که نرخ یادگیری و گرادیان $J(w)$ دو عاملی
هستند که موفقیت آموزش شبکه به آن‌ها بستگی دارد.

نرخ یادگیری می‌تواند به صورت پویا در طول فرآیند یادگیری تغییر داده شود. معمولا
نرخ یادگیری در ابتدای آموزش مقداری بالا دارد. هرچی آموزش شبکه پیش می‌رود، نرخ
یادگیری کاهش پیدا می‌کند. با این شیوه یادگیری، در ابتدای تغییرات وزن‌ها بیشتر
است و هرچی شبکه بیشتر به سمت همگرایی پیش برود، با کاهش نرخ یادگیری، تغییرات کمتر
می‌شود و شبکه با دقت بیشتری همگرا می‌شود. در سال‌های اخیر ADAM یکی از روش‌های
محبوب برای آموزش \gls{nn} است که به صورت خودکار تنظیم نرخ یادگیری را انجام
می‌دهد \cite{kingma2014adam}.

گرادیان تابع خطا نیز تاثیر به شدت زیادی در آموزش شبکه دارد. با توجه به شیوه کار
الگوریتم \gls{backpropagation}، گرادیان هر لایه تاثیر مستقیمی بر روی گرادیان
لایه‌های قبلی دارد. در نتیجه در صورتی که گرادیان‌ها در طول شبکه به صورت مناسبی
جریان نداشته باشند، آموزش شبکه با مشکلات جدی مواجه می‌شود و معمولا لایه‌های
ابتدایی آموزش صحیحی را دریافت نمی‌کند. موفقیت ساختارهایی مانند \gls{lstm} و
ارتباطهای رزیدوال که دقیقا با هدف جریان بهتر گرادیان‌ها طراحی شده‌اند، شاهدی بر
اهمیت این موضوع است.

توابع فعال‌سازی که در هر لایه استفاده می‌شود یکی دیگر از نکاتی هست که نیاز به
توجه بالا دارند. این توابع با معرفی کردن عاملی غیر خطی بین لایه‌ها به شبکه این
قابلیت را می‌دهند که الگوهای بسیار پیچیده‌تری را بتواند فرا بگیرد. همچنین این
توابع بر روی جریان گرادیان‌ها نیز تاثیر قابل توجهی دارند.

دو تا از توابع فعال‌سازی که به صورت گسترده، مخصوصا تا اوایل دهه‌ي ده میلادی،
استفاده می‌شود تابع سیگموید و تابع  تانژانت هیپربولیک است که در روابط زیر ضابطه
آن‌ها نشان داده شده است:
\begin{equation}
    sig(x) = \frac{1}{1 + e^{-x}}
\end{equation}
\begin{equation}
    tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
\end{equation}

با این وجود شبکه‌هایی که از این شبکه‌ها استفاده می‌کنند ممکن است از مشکل محو شدن
گرادیان در لایه‌های ابتدایی رنج ببرند \cite{bengio1994learning}. محو شدگی
گرادیان به شرایط گفته می‌شود که گرادیان تابع خطا در بخش‌هایی از شبکه مقداری
نزدیک به صفر پیدا کند. در نتیجه آن بخش‌های شبکه تقریبا هیچ آموزشی دریافت
نمی‌کنند یا آموزشی اشتباه دریافت می‌کنند.

برای حل این معضل، تابع فعال ساز ReLU پیشنهاد شد \cite{glorot2011deep}. این تابع
در سال‌های اخیر به عنوان تابع فعال‌ساز در اکثر فعالیت‌های منتشر شده استفاده شده
است. همچنین برای حل مشکل تغییر نکردن وزن نرون‌های غیر فعال تابع \lr{Leaky ReLU}
به عنوان یک جایگزین معرفی شد. در شکل زیر نمودار این چهار تابع فعال‌سازی رسم شده
است.
\begin{figure}[ht]
    \centering
    \includegraphics[width=12cm]{./statics/activation_functions.png}
    \caption{نمودار توابع فعال‌سازی معرفی شده}
\end{figure}

به عنوان تابع فعال‌سازی لایه آخر توصیه می‌شود از تابعی استفاده شود که بردی برابر
با بازه برچسب‌های \gls{dataset} داشته باشد. برای مثال اگر خروجی از جنس احتمال
است، تابع فعال‌سازی سیگموید که بردی آن بین صفر و یک است انتخاب مناسبی است. اگر
مسئله \gls{classification} با چند دسته است، تابع softmax توصیه می‌شود. این تابع
فعال سازی می‌تواند به ازای هر نرون خروجی، گرادیان مناسب را تولید کند. اگر مسئله
\gls{regression} است که خروجی محدودیتی ندارد استفاده از یک تابع فعال‌ساز خطی
توصیه می‌شود.

\subsection{تابع خطا}
آموزش در \gls{nn} با کمک تابع خطا رخ می‌دهد. با استفاده از تابع خطا می‌توانیم
توانایی شبکه در حل مسئله مورد نظر را ارزیابی کنیم. وقتی که مدل بتواند خروجی‌های
مناسب را به ازای ورودی‌های داده شده تولید کند، مقدار تابع خطا پایین خواهد بود.
هرچی که خروجی مدل از مقدار مورد نظر کمتر باشد، مقدار تابع خطا افزایش پیدا
می‌کند. پس در صورتی که ابزاری برای کاهش مقدار تابع خطا داشته باشیم می‌توان
جواب‌های درست به ازای ورودی‌های مختلف را به مدل آموزش دهیم. همچنین از مقدار تابع
خطا بر روی کل \gls{dataset} می‌توان استفاده کرد تا توانایی مدل‌های مختلف بر
مسئله مورد نظر را با هم مقایسه کنیم.

توابع خطا بسیار زیادی پیشنهاد شده‌اند که باید با توجه به ماهیت مسئله مورد هدف و
ساختار شبکه استفاده شده، تابع مناسب را از بین آن‌ها انتخاب کرد. به صورت کلی
توابع خطا را به دو دسته بزرگ می‌توان تقسیم کرد. توابع خطا مسائل
\gls{classification} و توابع خطا مسائل \gls{regression}. مسائل
\gls{classification} مسائلی هستند که در آن‌ها هدف اختصاص یک یا چند برچسب به
ورودی داده شده است. تابع Hinge و \gls{cross entropy} نمونه‌ای از توابع خطا مناسب
برای مسائل \gls{classification} هستند. مسائل \gls{regression} مسائلی هستند که در
آن‌ها هدف اختصاص یک یا چند مقدار عددی به ورودی داده شده است. \gls{mse} نمونه‌ای
از یک تابع خطا برای مسائل \gls{regression} است.

تابع \gls{cross entropy} محبوب‌ترین تابع خطا برای مسائل \gls{classification}
محسوب می‌شود. مقدار این تابع خطا بر اساس احتمال پیشبینی شده برای هر برچسب و
برچسب‌های صحیح هر نمونه محاسبه می‌شود و توسط رابطه زیر می‌توان آن را محسابه کرد:
\begin{equation}
    CrossEntropyLoss(y, y^\prime) = \sum_{c=1}^{M} y_i log(y_i^\prime)
\end{equation}
$M$ نشان دهنده تعداد برچسب‌های مختلف مسئله است که هر ورودی مطلق به یکی از آن‌ها
هست. $y_i$ نشان دهنده اختصاص برچسب $i$ به ورودی است. در صورتی که ورودی متعلق به
این گروه باشد، مقدار آن یک است. در غیر این صورت مقدار آن صفر است. همچنین
$y_i^\prime$ احتمال محاسبه توسط مدل برای برچسب $i$ است. معمولا از softmax به
عنوان تابع فعال سازی همراه این تابع خطا استفاده می‌شود.

در صورتی که تنها دو بر چسب مثبت و منفی داشته باشیم و بخواهیم احتمال یک خصوصیت در
ورودی را پیشبینی کنیم، از رابطه ساده شده زیر می‌توان استفاده کرد:
\begin{equation}
    BinaryCrossEntropyLoss(y, y^\prime) = -(y log(y^\prime)) + (1 - y)log(1 - y^\prime)
\end{equation}
sigmoid تابع فعال‌سازی است توصیه شده برای این تابع خطا است.

\gls{mse} یکی از توابع خطای محبوب برای مسائل \gls{regression} محسوب می‌شود. این
تابع خطا فاصله اقلیدوسی بین نقطه پیشبینی شده توسط شبکه و نقطه مورد هدف را محاسبه
می‌کند در نتیجه هرچی خروجی شبکه نامناسب‌تر باشد، مقدار تابع خطا بیشتر می‌شود.
مقدار خطا توسط رابطه زیر قابل مقایسه است:
\begin{equation}
    MSE(y, y^\prime) = \frac{1}{M} \sum_{c=1}^{M} (y_i - y_i^\prime)^2
\end{equation}
که $M$ اندازه ابعاد فضای خروجی است و $y^\prime$ نقطه پیشبینی شده توسط شبکه است.
همچنین $y$ نقطه هدف مورد نظر است.

\subsection{الگوریتم پس‌انتشار خطا}
\gls{backpropagation} یک روش برای محاسبه گرادیان تابع خطا نسبت به وزن‌های
سیناپس‌ها در شبکه‌های عصبی مصنوعی است. این روش معمولا به همراه یک الگوریتم
بهینه‌سازی، مانند \gls{gd}، به عنوان الگوریتم آموزش شبکه‌های عصبی مصنوعی به کار
گرفته می‌شود. هرچند معمولا به کل الگوریتم آموزش استفاده شده پس انتشار خطا گفته
می‌شود ولی در عمل، پس انتشار خطا تقریبا همان قاعده زنجیره‌ای مشتق است و تنها
وظیفه محاسبه گرادیان را بر عهده دارد.

الگوریتم بهینه سازی معمولا شامل دو گام است که متوالیا و به صورت پی‌در‌پی تکرار
می‌شوند: محاسبه گرادیان و بروزرسانی وزن‌ها. وقتی که یک بردار ورودی به شبکه داده
می‌شود، سیگنال‌های خروجی لایه‌ها به ترتیب محاسبه می‌شود تا خروجی آخرین لایه شبکه
به دست آید. به این مرحله \gls{feedforward} گفته می‌شود. سپس مقدار لایه آخر با
مقدار دلخواه ما مقایسه می‌شود و با توجه به اختلاف آن‌ها یک مقدار خطا محاسبه
می‌شود. سپس از این خطا نسبت به وزن‌های لایه آخر گرادیان گرفته می‌شود و این مقدار
گرادیان با توجه به قاعده زنجره‌ای مشتق به لایه‌های قبل منتقل می‌شود و سهم هر
سیناپس در مقدار خطا محاسبه می‌شود. این مرحله \gls{backpropagation} نام دارد. در
نهایت گرادیان محاسبه شده به الگوریتم بهینه‌سازی داده می‌شود تا وزن جدید هر
سیناپس محاسبه شود.

در طی فرآیند آموزش هر نرون یاد می‌گیرد طوری وزن‌های خود را تغییر دهد که نرون‌های
مختلف نشان دهنده خصوصیت‌های مختلفی از ورودی شبکه‌ باشد. وقتی که آموزش شبکه به
پایان رسید، وقتی ورودی که حاوی الگویی است که یک نرون شبکه به آن حساس شده است، به
شبکه داده می‌شود، آن نرون از خود فعالیت بیشتری نشان می‌دهد.

همان گونه که گفته شد برای محاسبه مقدار خطا در این روش نیاز به دانستن خروجی مطلوب
شبکه در مرحله آموزش است. به این جهت روش آموزش \gls{backpropagation}، معمولا یک
روش \gls{supervised learning} محسوب می‌شود هر چند در معماری‌هایی همچون
\gls{autoencoder}، از این الگوریتم برای آموزش بدون نظارت استفاده می‌شود.

هرچند که در تئوری لازمه این روش این است که توابع فعال‌ساز استفاده شده در شبکه
توابعی مشتق‌پذیر باشند، ولی در عمل توابعی همچون ReLU که در یک یا چند نقطه از
دامنه خود مشتق پذیر نیستند هم می‌توان استفاده کرد.

\subsection{الگوریتم‌های بهینه‌سازی}
آموزش شبکه‌های عصبی در اصل یک فرایند بهینه‌سازی است که طی آن تلاش می شود وزن‌های
شبکه به گونه‌ای تنظیم شوند که مقدار تابع خطا کمینه شود. در عمل \gls{sgd}
الگوریتم پایه‌ای است که برای آموزش شبکه‌های عصبی از آن استفاده می‌شود. این
الگوریتم به صورت پی‌درپی وزن‌های شبکه را با توجه به یک نمونه از \gls{dataset} به
گونه‌ای تغییر می‌دهد که مقدار تابع خطا کاهش پیدا کند. همچنین بار محاسباتی
\gls{sgd} در مقایسه با \gls{gd} که کل \gls{dataset} را در هر مرحله در نظر
می‌گرد به شدت کمتر است.

در طی فرآیند یادگیری میزان تاثیر هر مرحله توسط نرخ یادگیری کنترل می شود. نرخ
یادگیری پایین‌تر باعث می‌شود که درنهایت شبکه به نقطه‌ای بهینه‌تر همگرا شود در
حالی که زمان آموزش را به شدت افزایش می‌دهد. نرخ یادگیری بالاتر باعث می‌شود که
سرعت کاهش خطا بیشتر شود ولی ممکن است فرآیند یادگیری را بی‌ثبات کند و مانع همگرا
شدن شبکه شود. برای کنترل نوسانات \gls{SGD} پیشنهاد شد که از مفهوم \gls{momentum}
استفاده شود. \gls{momentum} که از قانون اول نیوتون الهام گرفته است، باعث همگرایی
سریع‌تر شبکه می‌شود و همچنین دقت نهایی در مقایسه با \gls{sgd} ساده افزایش می‌دهد.

ایده اصلی \gls{momentum} این است که بجای این که تنها از گرادیان تابع خطا در همان
مرحله برای بروزرسانی وزن‌های شبکه استفاده شود، از میانگین گرادیان‌ها در مراحل
اخیر استفاده شود. این رفتار را می‌توان توسط روابط زیر مدل کرد:
\begin{equation}
    v := \gamma v - \eta \nabla J(w)
\end{equation}
\begin{equation}
    w := w + v
\end{equation}
که $v$ مقدار \gls{momentum} را مشخص می‌کند. همچنین $\gamma$ ضریب تاثیر
\gls{momentum} است که مقداری بین صفر و یک دارد. یکی از مزایای مهم استفاده از
\gls{momentum} در آموزش شبکه این است که از گیر کردن شبکه در نقاط کمینه محلی
جلوگیری می‌کند. مقدار بالا $\gamma$ می‌تواند باعث شود که آموزش شبکه بی‌ثبات شود
و از نقاط کمینه دور شود. معمولا این مقدار برابر نیم قرار داده می‌شود و بعد از
گذشت مدتی از آموزش، مقدار آن افزایش داده می‌شود.

همچنین برای تنظیم مقدار صحیح نرخ یادگیری روش‌های متفاوتی پیشنهاد شده است. یکی از
این روش‌ها این است که مقدار نرخ یادگیری به صورت پویا در طول آموزش کاهش پیدا کند
تا شبکه در ابتدا سریع‌تر و در ادامه با دقت بالاتری آموزش داده شود. همچنین مقدار
دادن به نرخ یادگیری با توجه اندازه گرادیان‌ها در مراحل قبل نیز می‌تواند به
پایداری فرآیند آموزش کمک بسیاری بکند. نام این روش نرخ یادگیری انطباقی است.

Adagrad اولین الگوریتم بهینه‌سازی بود که توانست با موفقیت از نرخ یادگیری
انطباقی برای آموزش شبکه‌های استفاده کند. این الگوریتم با استفاده از نگهداری
مجموع مربعات گردایان مراحل قبل هر سیناپس، مقدار نرخ یادگیری را برای پارامترهایی
که کمتر تغییر می‌کند زیاد می‌کند و با کاهش نرخ یادگیری مانع تغییر پارامترهایی
می‌شود که تغییرات زیادی دارند. با توجه به این که مجموع مربعات گردایان‌ها همیشه
مقداری مثبت و افزایشی هست، نرخ یادگیری پس از مدتی به صفر نزدیک می‌شود و آموزش
شبکه متوقف می‌شود.

برای حل این معضل، الگوریتم Adadelta معرفی شد. این الگوریتم با معرفی یک پارامتر
$\beta_2$ میزان تاثییر گرادیان‌های گذشته را مشخص می‌کند و جلوی کم شدن بیش از حد
نرخ یادگیری را می‌گیرد. این الگوریتم از محاسبه مجموعه مربعات گرادیان‌ها از رابطه
زیر استفاده می‌کند:
\begin{equation}
    E[g^2]_t = \beta_2 E[g^2]_{t-1} + (1 - \beta_2)g_t^2
\end{equation}
که $E[g^2]_t$ مجموع مربعات گرادیان‌ها در مرحله $t$ است. همچنین $g_t^2$ مربعات
گردیان‌ها در مرحله $t$ است.

در زمان نوشتن این پایان‌نامه، Adam محبوب‌ترین الگوریتم بهینه‌سازی برای شبکه‌های
عصبی است \cite{kingma2014adam}. همچنین در عمل نشان داده شد است که اکثر شبکه‌هایی
که با این الگوریتم، به‌جای سایر الگوریتم‌های بهینه‌سازی، آموزش داده می‌شوند از
دقت بهتری بهره‌مند هستند.

Adam نیز از نرخ یادگیری انطباقی برای آموزش شبکه استفاده می‌کند. ولی بر خلاف
الگوریتم‌هایی که در بالا توضیح داده شد، نه تنها از مربع گرادیان‌های قبلی، بلکه
از مقدار گرادیان‌های مراحل قبل نیز برای محاسبه نرخ یادگیری بهره می‌برد. استفاده
از گردیان مرحله‌های قبلی بسیار شبیه الگوریتم‌های برپایه \gls{momentum} است. با
این تفاوت از نظر فیزیکی \gls{momentum} رفتاری شبیه به یک توپ دارد که در سراشیبی
در حرکت است. ولی Adam رفتاری مانند یک توپ سنگین با اصطحکاک دارد. در نتیجه این
الگوریتم سطوح صاف در فضای بهینه‌سازی را ترجیح می‌دهد. این رفتار منجر به توانای
بالاتر شبکه‌های آموزش دیده شده با Adam می‌شود.

تاثیر گرادیان‌ها و مربعات گرادیان‌های مراحل قبل به کمک $m_t$ و $v_t$ انجام
می‌شود که توسط روابط زیر قابل محاسبه هستند:
\begin{equation}
    m_t = \beta_1 m_{t-1} + (1 - \beta_1) g_t
\end{equation}
\begin{equation}
    v_t = \beta_2 v_{t-1} + (1 - \beta_2) g_t^2
\end{equation}
همچنین از صفر برای مقدار اولیه این متغیرها استفاده می‌شود. همچنین مشاهده شد که
این متغیرها در مراحل اولیه آموزش به صفر متمایل هستند که باعث کاهش سرعت آموزش
می‌شود. از این جهت از روی این متغیرها دو متغیر دیگر $\hat{m_t}$ و $\hat{v_t}$ با
کمک روابط زیر محاسبه می‌شود:
\begin{equation}
    \hat{m_t} = \frac{m_t}{1 - \beta_1}
\end{equation}
\begin{equation}
    \hat{v_t} = \frac{v_t}{1 - \beta_2}
\end{equation}

با محاسبه مقادیر بالا می‌توان از رابطه زیر استفاده کرد تا وزن‌های شبکه در زمان
$t$، $w_t$، را محاسبه کرد:
\begin{equation}
    w_{t+1} = w_{t} - \frac{\eta}{\sqrt{\hat{v_t}} + \epsilon} \hat{m_t}
\end{equation}

همچنین طی بررسی‌های انجام شده برای $\beta1$ مقدار ۰/۹، برای $\beta2$ مقدار ۰/۹۹۹
و برای $\epsilon$ مقدار $10^{-8}$ پیشنهاد شد.

\subsection{مشکلات شبکه‌های عصبی عمیق}
آموزش شبکه‌های عصبی مشکلات مختلفی دارد ولی دوتا از رایج‌ترین مشکلات \gls{overfit} و
زمان‌بر بودن آموزش آن‌ها است.

شبکه‌های عصبی عمیق به علت پارامترها و لایه‌های زیاد می‌توانند جزئی‌ترین اطلاعات
موجود در داده آموزشی را هم مدل کنند. این خاصیت باعث می‌شود که این شبکه‌ها به
سرعت بیش برازش شوند و خاصیت تعمیم‌دهی خود را از دست بدهند. برای همین از روش‌های
مختلفی برای مقابله با این پدیده در این شبکه‌ها استفاده می‌شود.

یکی از بدیهی‌ترین و کاراترین این روش‌ها افزایش داده‌های آموزشی است. هرچه
داده‌های آموزشی بیشتر و متنوع‌تر باشند شبکه در مقابل \gls{overfit} مقاوم‌تر می‌شود و
بهتر می‌تواند برای ورودی‌های جدید تصمیم مناسب را بگیرد. ولی این روش علی رغم
کارایی بالا به علت هزینه زیادی به همراه دارد نمی‌توان در همه موارد از آن استفاده
کرد.

یک راه دیگر برای مقابله با \gls{overfit} استفاده از روش‌های \gls{regularization}
است. این روش‌ها از طریق اضافه کردن جملاتی به تابع خطا، مانند مجموع مربع وزن
سیناپس‌ها، بر روی آزادی شبکه محدودیت‌ها قرار می‌دهند که باعث می‌شود شبکه از تمام
توان خود استفاده نکند و فقط از توان مورد نیاز بهره ببرد. \gls{regularization} را
می‌توان در روی اجزای مختلفی از شبکه اعمال کرد ولی وزن‌های سیناپسی و فعالیت
نرون‌ها دو مورد از رایج‌ترین موارد برای منظم‌سازی اند.

علاوه بر منظم‌سازی، dropout یک روش دیگر برای کنترل توان شبکه است. به این صورت که
در مرحله آموزش شبکه، در هرلایه، به صورت تصادفی، تعداد از نرون‌ها پوشیده می‌شوند
و خروجی آن‌ها به لایه بعد منتقل نمی‌شود. پس از پایان آموزش خروجی در نرون در
ضریبی ضرب می‌شود تا توزیع احتمالی سیگنال ورودی به هر لایه و نرون برابر مرحله
آموزش بماند. به این ترتیب شبکه‌ هر خصوصیت را به چند صورت یاد می‌گیرد و مانع
\gls{overfit} می‌شود.

شبکه‌های عصبی عمیق \gls{hyper parameter} بسیاری همچون تعداد و اندازه لایه‌ها،
مقدار اولیه وزن‌ها، نرخ یادگیری، ضرایب منظم‌سازی و ضریب dropout دارند. از طرفی
در هر بار آموزش یک شبکه عصبی عمیق، میلیون‌ها پارامتر باید یادگرفته شوند که مدت
زمان هر آموزش را بسیار طولانی می‌کند. برای همین امتحان تمامی مقادیر برای پیدا
کردن بهترین ساختار ممکن است به علت محدودیت زمانی ممکن نباشد. ولی با این حال
روش‌هایی مانند \gls{batching} برای کاهش زمان یادگیری وجود دارند. به این صورت که
بجای نمایش یک مثال در هر مرحله، مجموعه‌ای از مثال‌‌ها به شبکه نشان داده می‌شود و
وزن‌ها به اندازه میانگین تغییر وزن هر مثال، تغییر داده می‌شوند. دسته‌بندی باعث
کاهش زمان آموزش و افزایش عملکرد شبکه می‌شود.

همچنین استفاده از \gls{GPU} ها، به علت این که می‌توان در آن‌ها هزاران محاسبه همزمان
انجام داد، به شدت برای آموزش شبکه‌های عصبی عمیق مناسب است و زمان آموزش آن‌ها را
کاهش می‌دهد.

علاوه بر مشکلات اشاره شده، آموزش شبکه‌های عصبی عمیق از مشکلاتی دیگری همچنون محو
شدن گرادیان‌ هم رنج می‌برد که با استفاده از تابع‌های فعال‌سازی همچون ReLU و یا
استفاده از ساختارهایی همچون \gls{batch normalization} می‌توان با آن مقابله کرد.

\section{شبکه \gls{fully connected}}
لایه \gls{fully connected} پایه‌ای‌ترین ساختاری است که در شبکه‌های عصبی مورد
استفاده قرار می‌گیرد. این ساختار شبکه علاوه بر \gls{fully connected}، با اسمی
دیگری همچون لایه فشرده، به علت فشرده بودن ارتباط بین نرون‌ها، و \gls{mlp}، به
علت ریشه این ساختار، نیز شناخته می‌شود. در شکل زیر ساختار یک لایه \gls{fully
connected} و ارتباط بین نرون‌ها در آن نمایش داده شده است.
\begin{figure}[ht]
    \centering
    \includegraphics[height=5cm]{./statics/fully_connected.png}
    \caption{یک شبکه \gls{fully connected} با ۴ ورودی و ۳ خروجی}
\end{figure}

این لایه توسط رابطه زیر مدل می‌شود:
\begin{equation}
    y = f(W.x + b)
\end{equation}
که $x$ و $y$ بردارهایی از اعداد حقیقی هستند که به ترتیب متناظر با ورودی و خروجی
شبکه هستند. $W$ ماتریس وزن شبکه است که تعداد سطرهای آن برابر ابعاد ورودی و تعداد
ستون‌های آن برابر ابعاد خروجی است. همچنین $b$ بایاس شبکه است که عمکردی مانند عرض
از مبدا دارد و برداری از اعداد حقیقی با ابعادی برابر خروجی است. $f$ تابع
فعال‌سازی است که شبکه از آن استفاده می‌کند.

ورودی یک شبکه \gls{fully connected} تبدیل به برداری با ابعادی برابر با تعداد
نرون‌های خروجی می‌شود. در تئوری یک نرون خروجی می‌تواند حجم زیادی اطلاعات، در
صورتی که دقت محاسباتی به اندازه کافی باشد، را شامل شود. ولی در عمل معمولا هر
نرون یک ویژگی را فرا می‌گرد آن را نمایش می‌دهد. همچنین یک لایه با ابعادی پایین
می‌تواند در شبکه به عنوان یک تنگنا برای حجم اطلاعاتی که منتقل می‌شود ظاهر شود.

برای بسیاری از مسائل ابعاد خروجی به شدت از ابعاد ورودی کمتر است. در این شرایط
معمولا اندازه لایه‌های میانی برابر با اندازه‌ای ما بین تعداد نرون‌های ورودی و
خروجی قرار داده می‌شود. به این شکل اطلاعات در طول شبکه فشرده‌تر می‌شوند و فقط
اطلاعات مورد نیاز مسئله باقی می‌مانند.

\subsection{شبکه \gls{fully connected} در موسیقی}
در \gls{mir} از شبکه‌های \gls{fully connected} به صورت گسترده استفاده می‌شود تا
یک تبدیل بر روی هر فرم موسیقی ورودی اعمال شود و ویژگی‌های مورد نیاز از آن
استخراج شود. به این منظور بر روی هر فرم \gls{spec} یک شبکه \gls{fully connected}
یک‌سان اعمال می‌شود. با قرار دادن تعدادی لایه \gls{fully connected} بر روی
\gls{spec} می‌تواند انتظار داشت شبکه فرا بگیرد که فرکانس‌های ورودی به فضای دیگر
منتقل کند که حل مسئله در آن ساده‌تر است. برای مثال در صورتی که مسئله تشخیص
\glspl{pitch} فعال در هر فرم است و شبکه به تعداد \glspl{pitch} مورد نظر خروجی
دارد، می‌توان انتظار داشت که شبکه یادبگیرد هر نرون خروجی را با یکی از
\glspl{pitch} مورد نظر متناظر کند.

همچنین با توجه شکل تعریف شبکه \gls{fully connected} واضح است که این شبکه در
مقابل تغییر در مکان یا مقیاس فرکانس‌ها حساس است. برای مثال در صورتی که مسئله
مورد نظر تشخیص \glspl{pitch} فعال در هر فرم باشد، تنها با تغییر جزئی در کوک ساز
مورد بررسی، شبکه خروجی کاملا متفاوت و نادرست تولید خواهد کرد. واضحا این
آسیب‌پذیری برای بسیاری از مسائل مطلوب نیست و باعث کاهش دقت جدی در سیستم نهایی
می‌شود. از همین جهت این ساختار بیشتر از قبل محبوبیت ساختارهایی مانند \gls{cnn} و
\gls{rnn} مورد استفاده قرار می‌گرفته است. همچنین شبکه‌های \gls{fully connected}
به علت قابلیت تحلیل بالاتر نسبت به سایر ساختارها، در سیستم‌هایی به علت محدودیت
\gls{dataset} و زیر ساخت محاسباتی به صورت \gls{e2e} آموزش داده نمی‌شود، مورد
استفاده قرار می‌گرفته‌اند.